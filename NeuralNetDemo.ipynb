{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "from load_mnist import MNIST_Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a = MNIST_Loader()\n",
    "X_train, y_train = a.load_mnist('./data')\n",
    "X_test, y_test = a.load_mnist('./data', 't10k')\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "(78500,)\n",
      "(1010,)\n",
      "(78500,)\n",
      "(1010,)\n",
      "numerical gradient is 0.0 and actual gradient is 0.0\n",
      "numerical gradient is 0.000464447550641 and actual gradient is 0.0557337059656\n",
      "numerical gradient is -0.00081598876811 and actual gradient is -0.0979186523358\n",
      "numerical gradient is -6.53503278158e-05 and actual gradient is -0.00784203938131\n",
      "numerical gradient is 0.000150336772364 and actual gradient is 0.0180399849294\n",
      "numerical gradient is -0.000226944802506 and actual gradient is -0.0272333763277\n",
      "numerical gradient is -0.000486741924988 and actual gradient is -0.0584090310603\n",
      "numerical gradient is -0.000542851646301 and actual gradient is -0.0651421976847\n",
      "numerical gradient is 0.000371770687124 and actual gradient is 0.044612482476\n",
      "numerical gradient is -0.000396829701543 and actual gradient is -0.0476195639508\n",
      "numerical gradient is 0.000532662832953 and actual gradient is 0.080167800392\n",
      "numerical gradient is 0.00056038414975 and actual gradient is 0.067246103423\n",
      "numerical gradient is 4.17490877425e-05 and actual gradient is 0.00500989043233\n",
      "numerical gradient is 9.2168622956e-05 and actual gradient is 0.0110602349629\n",
      "numerical gradient is 0.000639761466914 and actual gradient is 0.076771375808\n",
      "numerical gradient is -0.000610809578916 and actual gradient is -0.0732971493319\n",
      "numerical gradient is -0.000413289010126 and actual gradient is -0.0495946814684\n",
      "numerical gradient is 5.55643566713e-05 and actual gradient is 0.00666772298095\n",
      "numerical gradient is -2.49433007582e-06 and actual gradient is -0.000299319633966\n",
      "numerical gradient is -0.000203848458113 and actual gradient is -0.0244618149696\n",
      "numerical gradient is -0.000798807919367 and actual gradient is -0.0958569505152\n",
      "numerical gradient is -0.000661955089853 and actual gradient is -0.0794346107925\n",
      "numerical gradient is 0.000177932959033 and actual gradient is 0.0213519551125\n",
      "numerical gradient is 0.000789312595728 and actual gradient is 0.0947175114958\n",
      "numerical gradient is -4.68328948955e-05 and actual gradient is -0.00561994755697\n",
      "numerical gradient is -0.000454026125141 and actual gradient is -0.0544823966079\n",
      "numerical gradient is 0.000679264573478 and actual gradient is 0.0815185470453\n",
      "numerical gradient is -0.000194303321877 and actual gradient is -0.0233089552637\n",
      "numerical gradient is 3.57873819468e-05 and actual gradient is 0.00429448588453\n",
      "numerical gradient is 0.000625970976387 and actual gradient is 0.0751331486959\n",
      "numerical gradient is 0.000650556982507 and actual gradient is 0.078066837818\n",
      "numerical gradient is -0.000286661723692 and actual gradient is -0.0343994069489\n",
      "numerical gradient is 0.000796766194355 and actual gradient is 0.0956119434377\n",
      "numerical gradient is 0.000124860539685 and actual gradient is 0.0149832647468\n",
      "numerical gradient is 0.000713492722682 and actual gradient is 0.0856191265152\n",
      "numerical gradient is -3.85092775446e-05 and actual gradient is -0.00462111343556\n",
      "numerical gradient is -0.00034525590209 and actual gradient is -0.0523404518822\n",
      "numerical gradient is -0.000248511117462 and actual gradient is -0.0298213339968\n",
      "numerical gradient is 0.000406953741816 and actual gradient is 0.0488344487594\n",
      "numerical gradient is -0.000705182401362 and actual gradient is -0.0846218881941\n",
      "numerical gradient is 0.000637825650074 and actual gradient is 0.0765390779911\n",
      "numerical gradient is -0.000669906164319 and actual gradient is -0.0803887395615\n",
      "numerical gradient is -0.000431187572758 and actual gradient is -0.0517425088753\n",
      "numerical gradient is 0.000169349773316 and actual gradient is 0.0203219725223\n",
      "numerical gradient is -0.000351936497722 and actual gradient is -0.0422323797588\n",
      "numerical gradient is 0.000299903710754 and actual gradient is 0.03598844481\n",
      "numerical gradient is -0.000318201040628 and actual gradient is -0.0381841247423\n",
      "numerical gradient is -0.000577733874962 and actual gradient is -0.0693280650301\n",
      "numerical gradient is -0.000776352344189 and actual gradient is -0.0931622813295\n",
      "numerical gradient is -0.000586450138229 and actual gradient is -0.0703740165024\n",
      "numerical gradient is 2.76800413701e-05 and actual gradient is 0.00332160475825\n",
      "numerical gradient is 0.000482682672498 and actual gradient is 0.0579219209521\n",
      "numerical gradient is 0.000391570775804 and actual gradient is 0.046988493563\n",
      "numerical gradient is 0.000584979671814 and actual gradient is 0.0701975606799\n",
      "numerical gradient is -0.000568142175084 and actual gradient is -0.0681770607557\n",
      "numerical gradient is -0.000366470933599 and actual gradient is -0.0439765118928\n",
      "numerical gradient is 0.000182280407657 and actual gradient is 0.0218736487594\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(n_output=10,\n",
    "                  n_features=X_train.shape[1],\n",
    "                  n_hidden=100,\n",
    "                  l2=0.1,\n",
    "                  epochs=10000,\n",
    "                  learning_rate=0.001,\n",
    "                  momentum_const=0.5,\n",
    "                  decay_rate=0.00001,\n",
    "                  dropout=True,\n",
    "                  minibatch_size=500, nesterov = True, check_gradients = True\n",
    "                 )\n",
    "nn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_error, test_error = get_train_test_error(classifier = nn, X = X_train, y = y_train,\n",
    "                                               num_iterations = 1, split = 0.2)\n",
    "print(\"test err: {}\".format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# k-fold CV\n",
    "mean_train_error, mean_test_error = cross_validate(classifier=nn, X=X_train, y=y_train, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print mean_train_error\n",
    "# print mean_test_error\n",
    "print(train_error)\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = nn.predict(X_train)\n",
    "print y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print y_train.shape[0]\n",
    "print y_train_pred.shape[0]\n",
    "diffs = y_train_pred  - y_train\n",
    "count = 0.\n",
    "for i in range(y_train.shape[0]):\n",
    "    if diffs[i] != 0:\n",
    "        count = count + 1\n",
    "print 100 - count*100/y_train.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = nn.predict(X_test)\n",
    "print y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print y_test_pred.shape[0]\n",
    "print y_test.shape[0]\n",
    "diffs = y_test_pred - y_test\n",
    "mistakes = []\n",
    "count = 0.\n",
    "for i in range(y_test.shape[0]):\n",
    "    if diffs[i] != 0:\n",
    "        count = count + 1\n",
    "        mistakes.append({\"actual\": y_test[i], \"predicted\": y_test_pred[i]})\n",
    "print 100 - count*100/y_test.shape[0]\n",
    "# initialize a data structure where each item will keep track of what mispredictions there were\n",
    "mistake_categories = [(i, {k:0 for k in range(10) if k != i}) for i in range(10)]\n",
    "for mistake in mistakes:\n",
    "    mistake_categories[mistake['actual']][1][mistake['predicted']]+=1\n",
    "\n",
    "for tup in mistake_categories:\n",
    "    for k, v in tup[1].items():\n",
    "        if v == 0: del tup[1][k] # remove keys where no mistakes were found \n",
    "\n",
    "for i in range(len(mistake_categories)): print mistake_categories[i]\n",
    "# tells us our mispredictions - ex: for images with label 2, we mispredicted a 0 twelve times, and mispredicted it as an 8 twenty times. \n",
    "# print [mistakes[i] for i in range(len(mistakes)) if mistakes[i]['actual']==4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
